{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c589ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we have 3 files in our project, we pasted the game code in this cell\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "class FlappyBird(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.width = 360\n",
    "        self.height = 600\n",
    "        self.velocity = 0\n",
    "        self.max_valocity = 7\n",
    "        self.start = True\n",
    "        self.gravity = 0.5\n",
    "        self.fps = 60\n",
    "        self.horizontal_velocity = 3\n",
    "        self.vertical_pillar_gap = 150\n",
    "        self.pillar_width = 60\n",
    "        self.pillar_height = self.height\n",
    "        self.render_mode = \"\"\n",
    "        self.done = False\n",
    "\n",
    "        pygame.init()\n",
    "        pygame.display.set_caption('')\n",
    "        self.display = pygame.display.set_mode((self.width, self.height))\n",
    "        self.font = pygame.font.SysFont('Arial_bold', 36)\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "        low = -1\n",
    "        high = 1\n",
    "        \n",
    "        self.observation_space=spaces.Box(low=low, high=high, shape=(3,), dtype = np.float32)\n",
    "        self.action_space=spaces.Discrete(2)\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.velocity = -10\n",
    "            self.start = True\n",
    "        if self.start:\n",
    "            self.bird.y += self.velocity\n",
    "            if self.velocity < self.max_valocity:\n",
    "                self.velocity += self.gravity\n",
    "\n",
    "        self.pillar_logic()\n",
    "\n",
    "        self.observation = self.get_obs()\n",
    "        self.reward = 1\n",
    "\n",
    "        self.collution_check()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        self.clock.tick(self.fps)\n",
    "\n",
    "        return self.observation, self.reward , self.done , False,  {}\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "\n",
    "        self.bird = pygame.Rect(25 , self.width //2 , 30 , 30)\n",
    "        self.pillars = list(self.get_pillars())\n",
    "        self.points = 0\n",
    "        self.done = False\n",
    "        \n",
    "        return self.get_obs() , {}\n",
    "    \n",
    "    def render(self, render_mode = \"human\"): \n",
    "        self.display.fill((37, 150, 190))\n",
    "        pygame.draw.rect(self.display , (200,200,0) , self.bird)\n",
    "        for pillar in self.pillars:\n",
    "            pygame.draw.rect(self.display , (0,125,0) , pillar)\n",
    "        str1 = str(self.points)\n",
    "        text = self.font.render(str1, True, (255, 255, 255))\n",
    "        self.display.blit(text, (self.width // 2 - (len(str1) * 36 / 2), 0))\n",
    "        pygame.display.update()\n",
    "\n",
    "        if self.done:\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "    def close(self):\n",
    "        pygame.quit()\n",
    "    \n",
    "    def pillar_logic(self):\n",
    "        if self.pillars[0].x + self.pillar_width < 0:\n",
    "            self.pillars.pop(0)\n",
    "            self.pillars.pop(0)\n",
    "            p1 , p2 = self.get_pillars()\n",
    "            self.pillars.append(p1)\n",
    "            self.pillars.append(p2)\n",
    "            self.points +=1 \n",
    "\n",
    "        if self.start:\n",
    "            for pillar in self.pillars:\n",
    "                pillar.x -= self.horizontal_velocity\n",
    "\n",
    "    def collution_check(self):\n",
    "        collide = False\n",
    "        for pillar in self.pillars:\n",
    "            collide = pygame.Rect.colliderect(pillar, self.bird)\n",
    "            if collide or self.bird.y < 0 or self.bird.y > self.height:\n",
    "                self.run = False\n",
    "                self.done = True\n",
    "                self.reward = -abs(self.bird.y - self.pillars[0].y + self.vertical_pillar_gap//2)\n",
    "                break\n",
    "\n",
    "\n",
    "    def get_pillars(self):\n",
    "        num = random.randint(1,self.height // self.vertical_pillar_gap)\n",
    "        p_d = pygame.Rect(self.width, num * self.vertical_pillar_gap, self.pillar_width, self.pillar_height)\n",
    "        p_u_y = p_d.y - self.vertical_pillar_gap - self.pillar_height\n",
    "        p_u = pygame.Rect(self.width, p_u_y, self.pillar_width, self.pillar_height)\n",
    "        return p_d , p_u\n",
    "    \n",
    "    def get_obs(self):\n",
    "        h = self.bird.y / self.height\n",
    "        d = (self.pillars[0].x - self.bird.x) /self.width\n",
    "        h_p = (self.bird.y - self.pillars[0].y + self.vertical_pillar_gap//2 ) / self.height\n",
    "\n",
    "        return np.array([h, d ,h_p])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# run\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from flappy_bird_env import *\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "import random\n",
    "from stable_baselines3 import SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab5f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "log_path = os.path.join(\"trainning\" , \"logs\")\n",
    "PPO_path = os.path.join(\"trainning\" , \"saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4585e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "env = FlappyBird()\n",
    "model = PPO('MlpPolicy' , env, verbose = 1,tensorboard_log = log_path)\n",
    "env.reset()\n",
    "env.get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b916d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainning\n",
    "env = FlappyBird()\n",
    "model = PPO('MlpPolicy' , env, verbose = 1,tensorboard_log = log_path)\n",
    "env.render_mode = \"\"\n",
    "model.learn(total_timesteps = 500000)\n",
    "model.save(\"bird\")\n",
    "# model.save_replay_buffer(\"car_replay_buffer\")\n",
    "# model.policy.save(\"car_policy_pendulum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28610b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "vec_env = make_vec_env(FlappyBird, n_envs=1)\n",
    "obs = vec_env.reset()\n",
    "while 1:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    print(\"Action: \", action)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
    "    vec_env.render_mode = \"human\"\n",
    "    vec_env.render()\n",
    "    if done:\n",
    "        # Note that the VecEnv resets automatically\n",
    "        # when a done signal is encountered\n",
    "        print(\"Goal reached!\", \"reward=\", reward)\n",
    "        vec_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# model load\n",
    "env = FlappyBird()\n",
    "model = PPO.load(\"bird\", env=env)\n",
    "\n",
    "# test\n",
    "vec_env = FlappyBird()\n",
    "obs, _ = vec_env.reset()\n",
    "while 1:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones,_, info = vec_env.step(action)\n",
    "    vec_env.render()\n",
    "    if dones:\n",
    "        vec_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8115751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc078ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3d347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
